import os
from hack.ClassifierState import ClassifierState
from hack.DataLoader import DataLoader

precision = 10
pseudocount = 0.001


class ClassifierAnnotationState(ClassifierState):
    def __init__(self, *args, **kwargs):
        ClassifierState.__init__(self, *args, **kwargs)


    def _emission(self, seq_x, x, seq_y, y, c):
        emissions = {
            ('A', 'A', 0): 0.013625452598054975,
            ('A', 'A', 1): 0.018483180413641397,
            ('A', 'A', 2): 0.015165707759094572,
            ('A', 'A', 3): 0.011374310439612487,
            ('A', 'A', 4): 0.009241649447403815,
            ('A', 'A', 5): 0.008530762450000924,
            ('A', 'A', 6): 0.0013034113097382003,
            ('A', 'A', 7): 0.00023708081363386409,
            ('A', 'A', 8): 0.00035556197986767924,
            ('A', 'A', 9): 1.1848116623381514e-07,
            ('A', 'C', 0): 0.019431029743511918,
            ('A', 'C', 1): 0.011018866940911042,
            ('A', 'C', 2): 0.006872026122727512,
            ('A', 'C', 3): 0.007819875452598034,
            ('A', 'C', 4): 0.0049763274629864695,
            ('A', 'C', 5): 0.003673034634414503,
            ('A', 'C', 6): 0.0005925243123353095,
            ('A', 'C', 7): 1.1848116623381514e-07,
            ('A', 'C', 8): 1.1848116623381514e-07,
            ('A', 'C', 9): 1.1848116623381514e-07,
            ('A', 'G', 0): 0.020378879073382438,
            ('A', 'G', 1): 0.011729753938313934,
            ('A', 'G', 2): 0.009004687114936185,
            ('A', 'G', 3): 0.009597092946105262,
            ('A', 'G', 4): 0.004739365130518839,
            ('A', 'G', 5): 0.0024882229720763517,
            ('A', 'G', 6): 0.0007110054785691246,
            ('A', 'G', 7): 0.00023708081363386409,
            ('A', 'G', 8): 1.1848116623381514e-07,
            ('A', 'G', 9): 1.1848116623381514e-07,
            ('A', 'T', 0): 0.007108988455195142,
            ('A', 'T', 1): 0.015521151257796018,
            ('A', 'T', 2): 0.010071017611040522,
            ('A', 'T', 3): 0.007345950787662772,
            ('A', 'T', 4): 0.0050948086292202845,
            ('A', 'T', 5): 0.006042657959090806,
            ('A', 'T', 6): 0.0005925243123353095,
            ('A', 'T', 7): 0.00035556197986767924,
            ('A', 'T', 8): 0.00011859964740004894,
            ('A', 'T', 9): 1.1848116623381514e-07,
            ('C', 'A', 0): 0.006753544956493697,
            ('C', 'A', 1): 0.01161127277208012,
            ('C', 'A', 2): 0.010189498777274337,
            ('C', 'A', 3): 0.00864924361623474,
            ('C', 'A', 4): 0.005924176792856991,
            ('C', 'A', 5): 0.00888620594870237,
            ('C', 'A', 6): 0.0016588548084396457,
            ('C', 'A', 7): 0.00023708081363386409,
            ('C', 'A', 8): 0.00023708081363386409,
            ('C', 'A', 9): 1.1848116623381514e-07,
            ('C', 'C', 0): 0.020023435574680993,
            ('C', 'C', 1): 0.019431029743511918,
            ('C', 'C', 2): 0.014810264260393127,
            ('C', 'C', 3): 0.01327000909935353,
            ('C', 'C', 4): 0.00793835661883185,
            ('C', 'C', 5): 0.008056837785065664,
            ('C', 'C', 6): 0.0014218924759720154,
            ('C', 'C', 7): 0.00023708081363386409,
            ('C', 'C', 8): 0.00023708081363386409,
            ('C', 'C', 9): 1.1848116623381514e-07,
            ('C', 'G', 0): 0.012914565600652085,
            ('C', 'G', 1): 0.010900385774677227,
            ('C', 'G', 2): 0.01161127277208012,
            ('C', 'G', 3): 0.007108988455195142,
            ('C', 'G', 4): 0.005805695626623176,
            ('C', 'G', 5): 0.006398101457792251,
            ('C', 'G', 6): 0.00106644897727057,
            ('C', 'G', 7): 0.00035556197986767924,
            ('C', 'G', 8): 0.00035556197986767924,
            ('C', 'G', 9): 1.1848116623381514e-07,
            ('C', 'T', 0): 0.003673034634414503,
            ('C', 'T', 1): 0.011729753938313934,
            ('C', 'T', 2): 0.012440640935716825,
            ('C', 'T', 3): 0.008293800117533294,
            ('C', 'T', 4): 0.006042657959090806,
            ('C', 'T', 5): 0.00793835661883185,
            ('C', 'T', 6): 0.0008294866448029397,
            ('C', 'T', 7): 0.0018958171409072758,
            ('C', 'T', 8): 0.00035556197986767924,
            ('C', 'T', 9): 0.00023708081363386409,
            ('G', 'A', 0): 0.007227469621428957,
            ('G', 'A', 1): 0.011492791605846302,
            ('G', 'A', 2): 0.009834055278572892,
            ('G', 'A', 3): 0.00864924361623474,
            ('G', 'A', 4): 0.006990507288961327,
            ('G', 'A', 5): 0.010307979943508152,
            ('G', 'A', 6): 0.001777335974673461,
            ('G', 'A', 7): 0.0007110054785691246,
            ('G', 'A', 8): 0.00023708081363386409,
            ('G', 'A', 9): 0.00011859964740004894,
            ('G', 'C', 0): 0.013625452598054975,
            ('G', 'C', 1): 0.010426461109741967,
            ('G', 'C', 2): 0.008293800117533294,
            ('G', 'C', 3): 0.00793835661883185,
            ('G', 'C', 4): 0.006042657959090806,
            ('G', 'C', 5): 0.006753544956493697,
            ('G', 'C', 6): 0.0018958171409072758,
            ('G', 'C', 7): 0.0004740431461014943,
            ('G', 'C', 8): 1.1848116623381514e-07,
            ('G', 'C', 9): 1.1848116623381514e-07,
            ('G', 'G', 0): 0.017061406418835613,
            ('G', 'G', 1): 0.014573301927925497,
            ('G', 'G', 2): 0.014691783094159312,
            ('G', 'G', 3): 0.011374310439612487,
            ('G', 'G', 4): 0.009478611779871447,
            ('G', 'G', 5): 0.01279608443441827,
            ('G', 'G', 6): 0.0034360723019468725,
            ('G', 'G', 7): 0.0023697418058425362,
            ('G', 'G', 8): 0.0004740431461014943,
            ('G', 'G', 9): 0.00011859964740004894,
            ('G', 'T', 0): 0.007819875452598034,
            ('G', 'T', 1): 0.01161127277208012,
            ('G', 'T', 2): 0.009004687114936185,
            ('G', 'T', 3): 0.007819875452598034,
            ('G', 'T', 4): 0.005687214460389361,
            ('G', 'T', 5): 0.009241649447403815,
            ('G', 'T', 6): 0.002251260639608721,
            ('G', 'T', 7): 0.00106644897727057,
            ('G', 'T', 8): 0.0004740431461014943,
            ('G', 'T', 9): 1.1848116623381514e-07,
            ('T', 'A', 0): 0.003554553468180688,
            ('T', 'A', 1): 0.00912316828117,
            ('T', 'A', 2): 0.012677603268184455,
            ('T', 'A', 3): 0.008293800117533294,
            ('T', 'A', 4): 0.006872026122727512,
            ('T', 'A', 5): 0.00912316828117,
            ('T', 'A', 6): 0.0016588548084396457,
            ('T', 'A', 7): 0.0014218924759720154,
            ('T', 'A', 8): 0.0004740431461014943,
            ('T', 'A', 9): 0.00023708081363386409,
            ('T', 'C', 0): 0.012440640935716825,
            ('T', 'C', 1): 0.009478611779871447,
            ('T', 'C', 2): 0.010663423442209597,
            ('T', 'C', 3): 0.003909996966882133,
            ('T', 'C', 4): 0.006161139125324621,
            ('T', 'C', 5): 0.006635063790259882,
            ('T', 'C', 6): 0.0015403736422058307,
            ('T', 'C', 7): 0.0009479678110367549,
            ('T', 'C', 8): 0.00023708081363386409,
            ('T', 'C', 9): 1.1848116623381514e-07,
            ('T', 'G', 0): 0.01232215976948301,
            ('T', 'G', 1): 0.01184823510454775,
            ('T', 'G', 2): 0.010781904608443412,
            ('T', 'G', 3): 0.007227469621428957,
            ('T', 'G', 4): 0.0052132897954541,
            ('T', 'G', 5): 0.006398101457792251,
            ('T', 'G', 6): 0.001777335974673461,
            ('T', 'G', 7): 0.0008294866448029397,
            ('T', 'G', 8): 0.0004740431461014943,
            ('T', 'G', 9): 1.1848116623381514e-07,
            ('T', 'T', 0): 0.008530762450000924,
            ('T', 'T', 1): 0.018720142746109027,
            ('T', 'T', 2): 0.016824444086367983,
            ('T', 'T', 3): 0.015639632424029833,
            ('T', 'T', 4): 0.011966716270781564,
            ('T', 'T', 5): 0.013388490265587345,
            ('T', 'T', 6): 0.0034360723019468725,
            ('T', 'T', 7): 0.00106644897727057,
            ('T', 'T', 8): 0.0005925243123353095,
            ('T', 'T', 9): 1.1848116623381514e-07,
        }
        return emissions[(seq_x[x], seq_y[y], round((precision-1)*c))]


class SupervisedHmmClassifierAnnotationStateTraining():
    def __init__(self):
        pass

    def transitions(self, seq_x, seq_y):
        labels = list(self.labels(seq_x, seq_y))

        counts = dict()
        for state in 'MXY':
            counts[state] = dict()
            for nextstate in 'MXY':
                counts[state][nextstate] = 0

        for i, state in enumerate(labels):
            if seq_x[i] == '-' and seq_y[i] == '-':
                continue
            j = i + 1
            while j < len(labels) and seq_x[i] == '-' and seq_y[i] == '-':
                j += 1
            if i < j < len(labels):
                nextstate = labels[j]
                counts[state][nextstate] += 1

        for state in 'MXY':
            s = float(sum(counts[state].values()))
            for nextstate in 'MXY':
                counts[state][nextstate] /= s

        return {
            k+k2: v2 for k, v in counts.iteritems() for k2, v2 in v.iteritems()
        }

    def emissions(self, seq_x, seq_y, ann_x, ann_y):
        labels = self.labels(seq_x, seq_y)
        classification = self.classification(seq_x, ann_x, seq_y, ann_y)
        counts = dict()
        for state in 'MXY':
            counts[state] = dict()
            for x in 'ACGT':
                if state == 'M':
                    for y in 'ACGT':
                        for c in xrange(precision):
                            counts[state][(x, y, c)] = pseudocount
                else:
                    counts[state][x] = pseudocount

        for state, x, y, c in zip(labels, seq_x, seq_y, classification):
            if state == 'X':
                if x != '-':
                    counts[state][x] += 1
            elif state == 'Y':
                if y != '-':
                    counts[state][y] += 1
            else:
                counts[state][(x, y, round((precision-1)*c))] += 1

        for state in 'MXY':
            s = float(sum(counts[state].values()))
            for x in 'ACGT':
                if state == 'M':
                    for y in 'ACGT':
                        for c in xrange(precision):
                            counts[state][(x, y, c)] /= s
                else:
                    counts[state][x] /= s

        return counts

    def starting(self):
        return [1/3.0, 1/3.0, 1/3.0]

    def get_probabilities(self, seq_x, ann_x, seq_y, ann_y):
        return\
            self.starting(),\
            self.transitions(seq_x, seq_y),\
            self.emissions(seq_x, seq_y, ann_x, ann_y)

    def labels(self, seq_x, seq_y):
        def state(i):
            if seq_x[i] == '-':
                return 'Y'
            if seq_y[i] == '-':
                return 'X'
            return 'M'

        if len(seq_x) != len(seq_y):
            return
        return (state(i) for i in xrange(len(seq_x)))

    def classification(self, seq_x, ann_x, seq_y, ann_y):
        if len(seq_x) != len(seq_y):
            return
        clf = ClassifierAnnotationState().clf
        ret = clf.multi_prepare_predict(
            (seq_x, pos, ann_x, seq_y, pos, ann_y)
            for pos in xrange(len(seq_x))
        )
        return ret


def main():
    path_to_data = "data/"

    dl = DataLoader()
    _, s_x, a_x, s_y, a_y = dl.loadSequence(
        os.path.join(path_to_data, 'train_sequences/simulated_alignment.fa')
    )
    training = SupervisedHmmClassifierAnnotationStateTraining()
    probabilities = training.get_probabilities(s_x, a_x, s_y, a_y)
    print(probabilities)


if __name__ == "__main__":
    main()
